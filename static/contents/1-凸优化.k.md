# 凸优化

凸优化是最优化问题中的性质非常好的一类问题，在实践中的应用也远远超乎人们的想象，凸优化即被用在自动控制系统、估计和信号处理、通信网络、电路设计、数据分析及建模、统计和金融方面。

发现某个问题是凸优化问题或能将其描述为凸优化问题将会大有裨益。最本质的好处就是对此问题可以用内点法或者其他凸优化方法进行可靠且迅速的求解。

对于很多一般性的优化方法，通常人们用它直截了当地试解待解的问题。凸优化就与此不同只有我们知道待解的问题是凸的，它的优越性才可能完整地体现出来。当然，很多优化问题是非凸的，判断某个问题是否凸或者将某个问题表述为凸优化的形式是比较困难的。

## 引言

优化问题是很多实际问题的抽象，现实中通常需要在一定的约束条件下找到问题的最大值或者最小值：

1. 如在资源有限的条件下获得最大的收益
2. 或者在确保收益的前提下使用最少的资源

这两个问题都是典型的优化问题，而且两者还是对偶问题，这个将在后面进行介绍。在常识上我们可以认识到优化问题并不总是有解的，但其中凸优化通常都是可解的，所以在解决优化问题之前，我们需要确定这个问题到底是不是凸优化，这至关重要。

### 定义

在数学上，为了给实际问题建模，需要使用精确的数学形式表示：

$$
\begin{aligned}
& \text{minimize} && f_0(x) \\
\end{aligned}
$$

$$
\begin{aligned}
& \text{subject to} && f_i(x) \le b_i, \quad i = 1, \dots, m
\end{aligned}
$$

- 优化变量：向量 $x = (x_1, \dots, x_n)$ 是一个n维向量，表示n个未知数。
- 目标函数：$f_0(x)$ 是目标函数，计算该函数的最小值。
- 约束函数：$f_i(x) \le b_i, \quad i = 1, \dots, m$ 表示 m 个约束条件。

对于优化问题，我们一般考虑具有特殊形式的目标函数和约束函数的优化问题，让我们由简入深吧，从形式上划分为两类线性规划和非线性规划。

### 线性规划

若优化问题中的目标函数和约束函数 $f_0, \dots, f_m$ 都是线性函数，即对任意的
$x, y \in \mathbb{R}^n \quad \text{和} \quad \alpha, \beta \in \mathbb{R}$ ，有

$$
f_i(\alpha x + \beta y) = \alpha f_i(x) + \beta f_i(y)
$$

- 该公式同时要求目标函数和约束函数都满足！！！

则此优化问题称为线性规划。若优化问题不是线性的，则称之为非线性规划（也有另外的理解，表示不一定是线性优化，即所有优化问题）。

### 凸函数

什么是凸优化？由凸函数构成的优化问题就称为凸优化，这就引出了凸函数的概念，什么是凸函数呢？

### 定义

对任意的
$x, y \in \mathbb{R}^n \text{ 和 } \alpha, \beta \in \mathbb{R}, \quad \alpha + \beta = 1, \quad \alpha \ge 0, \quad \beta \ge 0$
有：

$$
f_i(\alpha x + \beta y) \le \alpha f_i(x) + \beta f_i(y)
$$

符合上述要求的函数就是凸函数，这个式子该如何理解呢？因为 $x$ 和 $y$ 都是 $n$ 维向量，且
$\alpha + \beta = 1, \quad \alpha \ge 0, \quad \beta \ge 0$ ，那么 $f_i(\alpha x + \beta y)$
则表示可以由向量 $x$ 和向量 $y$ 表示的空间，其中满足
$f_i(\alpha x + \beta y) \le \alpha f_i(x) + \beta f_i(y)$
条件的点则构成长度和方向都受限的一个封闭空间。

### 定义证明

根据定义证明凸函数，通常使用 $\alpha = \theta, \quad \beta = 1 - \theta$ 来表示，其中
$\theta \in [0, 1]$ ，这样减少了变量个数，可以更好的计算：

例如函数 $f(x, y) = x^2 + y^2$

取任意两个点 $(x_1,y_1)$ 和 $(x_2,y_2)$ 为函数的两个点，

判断 $$ f(x, y) = x^2 + y^2$$ 是否为凸函数,当且仅当：

$$
f(\theta (x_1, y_1) + (1-\theta)(x_2, y_2)) \le \theta f(x_1,y_1) + (1 - \theta)f(x_2,y_2) , \quad \forall x_1, y_1,x_2,y_2 \in
\mathbb{R}^n, \theta \in [0,1].
$$

上式可以变形为

$$
f(\theta (x_1, y_1) + (1-\theta)(x_2, y_2)) \le f(x_2,y_2) + \theta (f(x_1,y_1) - f(x_2,y_2))
$$

上面内容有些过于复杂了，我们直接跳到结论吧，后面的内容才更重要。

## 判定公式

`海森矩阵（Hessian）半正定`是函数凸的`充要条件`，只在函数是`二阶可微`时成立。即为了证明函数是凸函数，通常从海森矩阵入手进行判断。

- 海森矩阵是在梯度的基础上继续求偏导所得到的
- 梯度就是对所有自变量求一阶偏导数后组成的列向量

### 半正定

| 性质               | 符号            | 判别方法                         |
| ------------------ | --------------- | -------------------------------- |
| 正定               | $(A \succ 0)$   | 所有顺序主子式 > 0               |
| 半正定             | $(A \succeq 0)$ | 所有特征值 ≥ 0（最常用、最准确） |
| 半正定（主子式法） | $(A \succeq 0)$ | 所有主子式（包括非连续的）≥ 0    |
